{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from buffer_pool_baseline.timer import Time\n",
    "from buffer_pool_baseline.cache import Cache\n",
    "from buffer_pool_baseline.strategy import EvictionStrategy\n",
    "from buffer_pool_baseline.environment import Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    \n",
    "    t = Time(0)\n",
    "    \n",
    "    c = Cache(cache_size, t, equate_id_to_value=True)\n",
    "    \n",
    "    start = random.randint(0, 20)\n",
    "    end = start + 5\n",
    "    \n",
    "    start_2 = start + random.randint(0, 5)\n",
    "    end_2 = start_2 + 5\n",
    "    \n",
    "    loop_size = random.randint(1, 3)\n",
    "    \n",
    "    select = Query(query_type = \"select\", time=t, parameters={\"start\": start, \"end\": end})\n",
    "    env = Query(query_type=\"join\", time=t, parameters={\"start_table_1\": start, \"end_table_1\": end, \n",
    "                                                       \"start_table_2\": start_2, \"end_table_2\": end_2})\n",
    "    env.set_query_cache(c)\n",
    "    \n",
    "    c.add_element(random.randint(0, 30))\n",
    "    c.add_element(random.randint(0, 30))\n",
    "    c.add_element(random.randint(0, 30))\n",
    "    c.add_element(random.randint(0, 30))\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multisetup():\n",
    "    \n",
    "    t = Time(0)\n",
    "    \n",
    "    c = Cache(cache_size, t, equate_id_to_value=True)\n",
    "    \n",
    "    start = random.randint(0, 20)\n",
    "    end = start + 5\n",
    "    \n",
    "    join_start = random.randint(end+10, end+15)\n",
    "    join_end = join_start + 5\n",
    "    \n",
    "    start_2 = join_start + random.randint(5, 10)\n",
    "    end_2 = start_2 + 5\n",
    "    \n",
    "    loop_size = random.randint(1, 3)\n",
    "    \n",
    "#     Change queries as per use case here! Name them select and join_query if you are lazy.\n",
    "\n",
    "    select = Query(query_type = \"sequential\", time=t, parameters={\"start\": start, \"end\": end, \"loop_size\": loop_size})\n",
    "#     join_query = Query(query_type = \"sequential\", time=t, parameters={\"start\": start_2, \"end\": end_2, \"loop_size\": loop_size})\n",
    "    \n",
    "#     select = Query(query_type = \"join\", time=t, parameters={\"start_table_1\": join_start, \"end_table_1\": join_end, \n",
    "#                                                             \"start_table_2\": start_2, \"end_table_2\": end_2})\n",
    "    \n",
    "#     select = Query(query_type=\"join\", time=t, parameters={\"start_table_1\": join_start, \"end_table_1\": join_end, \n",
    "#                                                        \"start_table_2\": start_2, \"end_table_2\": end_2})\n",
    "    \n",
    "    join_query = Query(query_type=\"sequential\", time=t, parameters={\"start\": join_start, \"end\": join_end, \"loop_size\": loop_size})\n",
    "    \n",
    "#     c.add_element(random.randint(100, 300))\n",
    "#     c.add_element(random.randint(100, 300))\n",
    "#     c.add_element(random.randint(100, 300))\n",
    "#     c.add_element(random.randint(100, 300))\n",
    "    select.set_query_cache(c)\n",
    "    join_query.set_query_cache(c)\n",
    "    \n",
    "    return select, join_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(query_type, table_size, loop_size):\n",
    "    t = Time()\n",
    "    if query_type == \"sequential\":\n",
    "        return Query(query_type=\"sequential\", time=t, parameters={\"start\": 0, \"end\": table_size, \"loop_size\": loop_size})\n",
    "    \n",
    "    if query_type == \"select\":\n",
    "        return Query(query_type=\"select\", time=t, parameters={\"start\": 0, \"end\": table_size})\n",
    "    \n",
    "    if query_type == \"join\":\n",
    "        return Query(query_type=\"join\", time=t, parameters={\"start_table_1\": 0, \"end_table_1\": 10, \n",
    "                                                            \"start_table_2\": 0, \"end_table_2\": 10})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_steps_per_query(table_size, cache_size, loop_size):\n",
    "    time_steps = {}\n",
    "    \n",
    "    query_types = [\"sequential\", \"select\", \"join\"]\n",
    "    \n",
    "    for query in query_types:\n",
    "        t = Time(0)\n",
    "        env = get_query(query, table_size, loop_size)\n",
    "        c = Cache(cache_size, t, equate_id_to_value=True)\n",
    "        env.set_query_cache(c)\n",
    "\n",
    "        while not env.is_done():\n",
    "            env.step(\"mru\")\n",
    "\n",
    "        time_steps[query] = env.time.now()\n",
    "    \n",
    "    return time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_queries(query_type, time_step, max_time_steps):\n",
    "    return max_time_steps[query_type] + time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_steps = get_time_steps_per_query(10, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "epsilon_greedy = True\n",
    "alpha_decay = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values_cumulative = []\n",
    "old_q = np.zeros([1000, 4])\n",
    "q_table = np.zeros([1000, 4])\n",
    "cache_size = 4\n",
    "number_of_runs = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_div = number_of_runs / 6\n",
    "alpha_div = number_of_runs / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(query, q_table):\n",
    "    cache_map_policy = []\n",
    "    \n",
    "    start_index = max_time_steps[query.query_type]\n",
    "    \n",
    "    reward = 0\n",
    "    \n",
    "    for d in q_table[start_index:]:\n",
    "        action = [\"mru\", \"lru\", \"lfu\", \"fifo\"][np.argmax(d)]\n",
    "        cache_map_policy.append({\"action\": action, \n",
    "                                 \"cache\": query.cache.cache_map.copy().keys(),\n",
    "                                \"which_element\": query.parameters.copy()})\n",
    "        query.step(action)\n",
    "        \n",
    "        if query.is_done():\n",
    "            break\n",
    "    \n",
    "    hits, misses = query.step()\n",
    "    reward = hits -  misses\n",
    "    return hits, misses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(query, action = \"lru\"):\n",
    "    cache_map_baseline = []\n",
    "    \n",
    "    while not query.is_done():\n",
    "        query.step(action)\n",
    "        cache_map_baseline.append({\"cache\": query.cache.cache_map.copy().keys(), \n",
    "                                   \"which_element\": query.parameters.copy()})\n",
    "        \n",
    "    hits, misses = query.step()\n",
    "    return hits, misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_query_reward(env):\n",
    "    params_baseline = env.parameters.copy()\n",
    "    params_random = env.parameters.copy()\n",
    "    params_policy = env.parameters.copy()\n",
    "    query_type = env.query_type\n",
    "    \n",
    "    t = Time(0)\n",
    "    query_baseline = Query(query_type=query_type, parameters=params_baseline, time=t)\n",
    "    c = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "    query_baseline.set_query_cache(c)\n",
    "    \n",
    "    query_baseline_random = Query(query_type=query_type, parameters=params_random, time=t)\n",
    "    c2 = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "    query_baseline_random.set_query_cache(c2)\n",
    "    \n",
    "    query_policy = Query(query_type=query_type, parameters=params_policy, time=t)\n",
    "    c3 = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "    query_policy.set_query_cache(c3)\n",
    "    \n",
    "    hits_policy, misses_policy = evaluate_policy(query_policy, q_table)\n",
    "    hits_baseline, misses_baseline = get_baseline(query_baseline)\n",
    "    hits_random, misses_random = get_baseline(query_baseline_random, \"random\")\n",
    "    \n",
    "    return {\"hits_random\" : hits_random, \"misses_random\": misses_random, \n",
    "            \"hits_baseline\": hits_baseline, \"misses_baseline\": misses_baseline,\n",
    "           \"hits_policy\": hits_policy, \"misses_policy\": misses_policy, \"tm\": query_baseline.time.now()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_state = []\n",
    "\n",
    "def run_multiple():\n",
    "    global epsilon, alpha\n",
    "    \n",
    "    cum_reward_plot = []\n",
    "    q_values_cumulative = []\n",
    "    reward_policy = []\n",
    "    \n",
    "    for i in tqdm(range(1, number_of_runs+1)):\n",
    "\n",
    "        q1, q2 = multisetup()\n",
    "        state = encode_queries(q1.query_type, q1.time.now(), max_time_steps)\n",
    "\n",
    "        penalties, reward, = 0, 0\n",
    "        done = False\n",
    "        previous_hit, previous_miss = 0, 0\n",
    "        cum_reward = 0\n",
    "        tm = 0\n",
    "        \n",
    "        old_q = q_table.copy()\n",
    "        \n",
    "        while (not q1.is_done() or not q2.is_done()):\n",
    "            if q1.is_done():\n",
    "                env = q2\n",
    "            else:\n",
    "                env = q1\n",
    "            \n",
    "            if epsilon_greedy:\n",
    "                epsilon = 0.1/pow(10, round(i/epsilon_div))\n",
    "            \n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = random.choice(env.actions) # Explore action space\n",
    "            else:\n",
    "                _action_ = np.argmax(q_table[state]) # Exploit learned values\n",
    "                action = [\"mru\", \"lru\", \"lfu\", \"fifo\"][_action_]\n",
    "\n",
    "            hits, miss = env.step(action)\n",
    "            next_state = encode_queries(env.query_type, env.time.now(), max_time_steps)\n",
    "            encoded_state.append(next_state)\n",
    "        \n",
    "            reward = hits - previous_hit\n",
    "            penalties = miss - previous_miss\n",
    "\n",
    "            previous_hit = hits\n",
    "            previous_miss = miss\n",
    "\n",
    "            _action_ = [\"mru\", \"lru\", \"lfu\", \"fifo\"].index(action)\n",
    "\n",
    "            old_value = q_table[state, _action_]\n",
    "            next_max = np.max(q_table[next_state])\n",
    "\n",
    "            r = reward - penalties\n",
    "            \n",
    "            if alpha_decay:\n",
    "                alpha = 0.01/pow(10, round(i/alpha_div))\n",
    "                \n",
    "            new_value = (1 - alpha) * old_value + alpha * (r + gamma * next_max)\n",
    "            \n",
    "            q_table[state, _action_] = new_value\n",
    "            state = next_state\n",
    "            cum_reward += r\n",
    "            tm += 1\n",
    "            \n",
    "        q_values_cumulative.append({\"q_values_cumulative\": sum(sum(abs(old_q - q_table)))})\n",
    "        \n",
    "        cum_reward_plot.append({\"reward\": cum_reward, \"epoch\": i, \"time\": tm})\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            total_hits = 0\n",
    "            total_misses = 0\n",
    "\n",
    "            for i in range(100):\n",
    "                q1, q2 = multisetup()\n",
    "                r1 = compare_query_reward(q1) \n",
    "                r2 = compare_query_reward(q2)\n",
    "\n",
    "                total_r = {}\n",
    "                for x, y in r1.items():\n",
    "                    total_r[x] = y\n",
    "\n",
    "                for x, y in r2.items():\n",
    "                    total_r[x] += y\n",
    "                    \n",
    "                tm = q1.time.now() + q2.time.now()\n",
    "                total_hits += total_r[\"hits_policy\"] / total_r[\"tm\"]\n",
    "                total_misses += total_r[\"misses_policy\"] / total_r[\"tm\"]\n",
    "            \n",
    "            reward_policy.append({\"Total Hits\": total_hits, \"Total Misses\": total_misses})\n",
    "            \n",
    "    return cum_reward_plot, q_values_cumulative, reward_policy\n",
    "    print(\"Training finished.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▏                                                                      | 30287/1000000 [01:44<51:31, 313.68it/s]"
     ]
    }
   ],
   "source": [
    "cum_reward_plot, q_values_cumulative, reward = run_multiple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_reward(query_type):\n",
    "    \n",
    "    env = setup()\n",
    "    params_baseline = env.parameters.copy()\n",
    "    params_random = env.parameters.copy()\n",
    "    params_policy = env.parameters.copy()\n",
    "    \n",
    "    t = Time(0)\n",
    "    query_baseline = Query(query_type=query_type, parameters=params_baseline, time=t)\n",
    "    c = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "    query_baseline.set_query_cache(c)\n",
    "    \n",
    "    query_baseline_random = Query(query_type=query_type, parameters=params_random, time=t)\n",
    "    c2 = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "    query_baseline_random.set_query_cache(c2)\n",
    "    \n",
    "    query_policy = Query(query_type=query_type, parameters=params_policy, time=t)\n",
    "    c3 = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "    query_policy.set_query_cache(c3)\n",
    "    \n",
    "    hits_policy, misses_policy = evaluate_policy(query_policy, q_table)\n",
    "    hits_baseline, misses_baseline = get_baseline(query_baseline)\n",
    "    hits_random, misses_random = get_baseline(query_baseline_random, \"random\")\n",
    "    \n",
    "    return {\"hits_random\" : hits_random, \"misses_random\": misses_random, \n",
    "            \"hits_baseline\": hits_baseline, \"misses_baseline\": misses_baseline,\n",
    "           \"hits_policy\": hits_policy, \"misses_policy\": misses_policy, \"tm\": query_baseline.time.now()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_metrics[\"Total Hits\"]).plot()\n",
    "plt.title(\"Number of hits for multiple sequential + sequential queries for empty cache and 4 actions\")\n",
    "plt.xlabel(\"Validation Run\")\n",
    "plt.ylabel(\"Hits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1, q2 = multisetup()\n",
    "\n",
    "# h1, miss1 = evaluate_policy(q1, q_table)\n",
    "# h2, miss2 = evaluate_policy(q2, q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1, miss1, h2, miss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1, q2 = multisetup()\n",
    "# get_baseline(q1), get_baseline(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_value = pd.DataFrame(q_values_cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_q_value.min(), df_q_value.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cum_reward_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"r\"] = df[\"reward\"] / df[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reward.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"rolling_mean\"] = df[\"r\"].rolling(200).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_value = pd.DataFrame(q_values_cumulative)\n",
    "df_q_value.head()\n",
    "df_q_value[\"rolling\"] = df_q_value.rolling(1000).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_value.plot(figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=\"rolling_mean\", x=\"epoch\", figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "actions = [\"mru\", \"lru\", \"lfu\", \"fifo\"]\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(q_table[66:111])\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(actions)))\n",
    "\n",
    "ax.set_xticklabels(actions)\n",
    "\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(q_table[66:111])):\n",
    "    for j in range(len(actions)):\n",
    "        #print(q_table[66+i, j])\n",
    "        text = ax.text(j, i, round(q_table[66+i, j],4),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "fig.set_figheight(40)\n",
    "fig.set_figwidth(20)\n",
    "ax.set_title(\"Actions chosen by our model for each time step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def run_single():\n",
    "#     global epsilon\n",
    "    \n",
    "#     cum_reward_plot = []\n",
    "#     encoded_state = []\n",
    "\n",
    "#     for i in tqdm(range(1, number_of_runs)):\n",
    "\n",
    "#         env = setup()\n",
    "#         state = encode_queries(env.query_type, env.time.now(), max_time_steps)\n",
    "\n",
    "#         penalties, reward, = 0, 0\n",
    "#         done = False\n",
    "#         previous_hit, previous_miss = 0, 0\n",
    "#         cum_reward = 0\n",
    "#         tm = 0\n",
    "\n",
    "#         while not done:\n",
    "\n",
    "#             if random.uniform(0, 1) < epsilon:\n",
    "#                 action = random.choice(env.actions) # Explore action space\n",
    "#             else:\n",
    "#                 _action_ = np.argmax(q_table[state]) # Exploit learned values\n",
    "#                 action = \"mru\" if _action_ == 0 else \"lru\"\n",
    "\n",
    "#             hits, miss = env.step(action)\n",
    "#             next_state = encode_queries(env.query_type, env.time.now(), max_time_steps)\n",
    "#             encoded_state.append(next_state)\n",
    "\n",
    "#             reward = hits - previous_hit\n",
    "#             penalties = miss - previous_miss\n",
    "\n",
    "#             previous_hit = hits\n",
    "#             previous_miss = miss\n",
    "\n",
    "#             done = env.done\n",
    "\n",
    "#             _action_ = 0 if action == \"mru\" else 1\n",
    "\n",
    "#             old_value = q_table[state, _action_]\n",
    "#             next_max = np.max(q_table[next_state])\n",
    "\n",
    "#             r = reward - penalties\n",
    "#             new_value = (1 - alpha) * old_value + alpha * (r + gamma * next_max)\n",
    "#             q_table[state, _action_] = new_value\n",
    "#             state = next_state\n",
    "#             cum_reward += r\n",
    "#             tm += 1\n",
    "\n",
    "#         old_q = q_table.copy()\n",
    "\n",
    "#         cum_reward_plot.append({\"reward\": cum_reward, \"epoch\": i, \"time\": tm})\n",
    "\n",
    "#     print(\"Training finished.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
