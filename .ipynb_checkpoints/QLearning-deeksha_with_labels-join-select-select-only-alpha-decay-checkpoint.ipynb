{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from buffer_pool_baseline.timer import Time\n",
    "from buffer_pool_baseline.cache import Cache\n",
    "from buffer_pool_baseline.strategy import EvictionStrategy\n",
    "from buffer_pool_baseline.environment import Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    \n",
    "    t = Time(0)\n",
    "    \n",
    "    c = Cache(cache_size, t, equate_id_to_value=True)\n",
    "    \n",
    "    start = random.randint(0, 20)\n",
    "    end = start + 5\n",
    "    \n",
    "    start_2 = start + random.randint(0, 5)\n",
    "    end_2 = start_2 + 5\n",
    "    \n",
    "    loop_size = random.randint(1, 3)\n",
    "    \n",
    "    select = Query(query_type = \"select\", time=t, parameters={\"start\": start, \"end\": end})\n",
    "    env = Query(query_type=\"join\", time=t, parameters={\"start_table_1\": start, \"end_table_1\": end, \n",
    "                                                       \"start_table_2\": start_2, \"end_table_2\": end_2})\n",
    "    env.set_query_cache(c)\n",
    "    \n",
    "    c.add_element(random.randint(0, 30))\n",
    "    c.add_element(random.randint(0, 30))\n",
    "    c.add_element(random.randint(0, 30))\n",
    "    c.add_element(random.randint(0, 30))\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multisetup():\n",
    "    \n",
    "    t = Time(0)\n",
    "    \n",
    "    c = Cache(cache_size, t, equate_id_to_value=True)\n",
    "    \n",
    "    start = random.randint(0,20)\n",
    "    end = start + random.randint(3,10)\n",
    "    \n",
    "    join_start = random.randint(end+6, end+11)\n",
    "    join_end = join_start + random.randint(3, 8)\n",
    "    \n",
    "    start_2 = join_start + random.randint(5, 10)\n",
    "    end_2 = start_2 + random.randint(11,16)\n",
    "    \n",
    " \n",
    "    \n",
    "    loop_size = random.randint(1, 3)\n",
    "    \n",
    "#     Change queries as per use case here! Name them select and join_query if you are lazy.\n",
    "\n",
    "    select = Query(query_type = \"sequential\", time=t, parameters={\"start\": start, \"end\": end, \"loop_size\": loop_size})\n",
    "#    join_query = Query(query_type = \"sequential\", time=t, parameters={\"start\": start_2, \"end\": end_2, \"loop_size\": loop_size})\n",
    "    \n",
    "    select = Query(query_type = \"sequential\", time=t, parameters={\"start\": join_start, \"end\": join_end, \"loop_size\": loop_size})\n",
    "                                                                      \n",
    "    #join_query = Query(query_type=\"sequential\", time=t, parameters={\"start\": join_start, \"end\": join_end, \"loop_size\": loop_size})\n",
    "    \n",
    "    c.add_element(random.randint(100, 300))\n",
    "    c.add_element(random.randint(100, 300))\n",
    "    c.add_element(random.randint(100, 300))\n",
    "    c.add_element(random.randint(100, 300))\n",
    "    select.set_query_cache(c)\n",
    "    join_query.set_query_cache(c)\n",
    "    \n",
    "    return join_query,select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(query_type, table_size, loop_size):\n",
    "    t = Time()\n",
    "    if query_type == \"sequential\":\n",
    "        return Query(query_type=\"sequential\", time=t, parameters={\"start\": 0, \"end\": table_size, \"loop_size\": loop_size})\n",
    "    \n",
    "    if query_type == \"select\":\n",
    "        return Query(query_type=\"select\", time=t, parameters={\"start\": 0, \"end\": table_size})\n",
    "    \n",
    "    if query_type == \"join\":\n",
    "        return Query(query_type=\"join\", time=t, parameters={\"start_table_1\": 0, \"end_table_1\": 10, \n",
    "                                                            \"start_table_2\": 0, \"end_table_2\": 10})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_steps_per_query(table_size, cache_size, loop_size):\n",
    "    time_steps = {}\n",
    "    \n",
    "    query_types = [\"sequential\", \"select\", \"join\"]\n",
    "    \n",
    "    for query in query_types:\n",
    "        t = Time(0)\n",
    "        env = get_query(query, table_size, loop_size)\n",
    "        c = Cache(cache_size, t, equate_id_to_value=True)\n",
    "        env.set_query_cache(c)\n",
    "\n",
    "        while not env.is_done():\n",
    "            env.step(\"mru\")\n",
    "\n",
    "        time_steps[query] = env.time.now()\n",
    "    \n",
    "    return time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_queries(query_type, time_step, max_time_steps):\n",
    "    return max_time_steps[query_type] + time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_steps = get_time_steps_per_query(10, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0001\n",
    "gamma = 0.6\n",
    "epsilon = 0.1\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "epsilon_greedy = True\n",
    "alpha_decay = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values_cumulative = []\n",
    "old_q = np.zeros([1000, 2])\n",
    "q_table = np.zeros([1000, 2])\n",
    "cache_size = 4\n",
    "number_of_runs = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_div = number_of_runs / 4\n",
    "alpha_div = number_of_runs / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(query, q_table):\n",
    "    cache_map_policy = []\n",
    "    \n",
    "    start_index = max_time_steps[query.query_type]\n",
    "    \n",
    "    reward = 0\n",
    "    \n",
    "    for d in q_table[start_index:]:\n",
    "        action = [\"mru\", \"lru\"][np.argmax(d)]\n",
    "        cache_map_policy.append({\"action\": action, \n",
    "                                 \"cache\": query.cache.cache_map.copy().keys(),\n",
    "                                \"which_element\": query.parameters.copy()})\n",
    "        query.step(action)\n",
    "        \n",
    "        if query.is_done():\n",
    "            break\n",
    "    \n",
    "    hits, misses = query.step()\n",
    "    reward = hits -  misses\n",
    "    return hits, misses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(query, action = \"lru\"):\n",
    "    cache_map_baseline = []\n",
    "    \n",
    "    while not query.is_done():\n",
    "        query.step(action)\n",
    "        cache_map_baseline.append({\"cache\": query.cache.cache_map.copy().keys(), \n",
    "                                   \"which_element\": query.parameters.copy()})\n",
    "        \n",
    "    hits, misses = query.step()\n",
    "    return hits, misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_query_reward(env, q_table, t, c, c2,c3):\n",
    "    \n",
    "    params_baseline = env.parameters.copy()\n",
    "    params_random = env.parameters.copy()\n",
    "    params_policy = env.parameters.copy()\n",
    "    query_type = env.query_type\n",
    "    \n",
    "    query_baseline = Query(query_type=query_type, parameters=params_baseline, time=t)\n",
    "    \n",
    "    query_baseline.set_query_cache(c)\n",
    "    \n",
    "    query_baseline_random = Query(query_type=query_type, parameters=params_random, time=t)\n",
    "    query_baseline_random.set_query_cache(c2)\n",
    "    \n",
    "    query_policy = Query(query_type=query_type, parameters=params_policy, time=t)\n",
    "    query_policy.set_query_cache(c3)\n",
    "    \n",
    "    hits_policy, misses_policy = evaluate_policy(query_policy, q_table)\n",
    "    hits_baseline, misses_baseline = get_baseline(query_baseline)\n",
    "    hits_random, misses_random = get_baseline(query_baseline_random, \"random\")\n",
    "    \n",
    "    return {\"hits_baseline\": hits_baseline, \"misses_baseline\": misses_baseline,\n",
    "           \"hits_policy\": hits_policy, \"misses_policy\": misses_policy, \"tm\": query_baseline.time.now()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_state = []\n",
    "\n",
    "# number_of_runs = 1\n",
    "def run_multiple():\n",
    "    global epsilon, alpha\n",
    "    \n",
    "    cum_reward_plot = []\n",
    "    q_values_cumulative = []\n",
    "    reward_policy = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(1, number_of_runs+1)):\n",
    "\n",
    "        q1, q2 = multisetup()\n",
    "        state = encode_queries(q1.query_type, q1.time.now(), max_time_steps)\n",
    "\n",
    "        penalties, reward, = 0, 0\n",
    "        done = False\n",
    "        previous_hit, previous_miss = 0, 0\n",
    "        cum_reward = 0\n",
    "        tm = 0\n",
    "        \n",
    "        old_q = q_table.copy()\n",
    "        \n",
    "        while (not q1.is_done() or not q2.is_done()):\n",
    "            if q1.is_done():\n",
    "                env = q2\n",
    "            else:\n",
    "                env = q1\n",
    "            \n",
    "            if epsilon_greedy:\n",
    "                epsilon = 0.1/pow(10, round(i/epsilon_div))\n",
    "            \n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = random.choice([\"mru\", \"lru\"]) # Explore action space\n",
    "            else:\n",
    "                _action_ = np.argmax(q_table[state]) # Exploit learned values\n",
    "                action = [\"mru\", \"lru\"][_action_]\n",
    "\n",
    "            hits, miss = env.step(action)\n",
    "            next_state = encode_queries(env.query_type, env.time.now(), max_time_steps)\n",
    "            encoded_state.append(next_state)\n",
    "        \n",
    "            reward = hits - previous_hit\n",
    "            penalties = miss - previous_miss\n",
    "\n",
    "            previous_hit = hits\n",
    "            previous_miss = miss\n",
    "\n",
    "            _action_ = [\"mru\", \"lru\"].index(action)\n",
    "\n",
    "            old_value = q_table[state, _action_]\n",
    "            next_max = np.max(q_table[next_state])\n",
    "\n",
    "            r = reward - penalties\n",
    "#             if r > 0:\n",
    "#                 print(q1.parameters, q2.parameters)\n",
    "            \n",
    "            if alpha_decay:\n",
    "                alpha = 0.01/pow(10, round(i/alpha_div))\n",
    "                \n",
    "            new_value = (1 - alpha) * old_value + alpha * (r + gamma * next_max)\n",
    "            \n",
    "            q_table[state, _action_] = new_value\n",
    "            state = next_state\n",
    "            cum_reward += r\n",
    "            tm += 1\n",
    "            \n",
    "        q_values_cumulative.append({\"q_values_cumulative\": sum(sum(abs(old_q - q_table)))})\n",
    "        hits, misses = q1.step()\n",
    "        hits2, misses2 = q2.step()\n",
    "        \n",
    "        cum_reward_plot.append({\"reward\": cum_reward, \"epoch\": i, \"time\": tm, \"hits\": hits+hits2, \"misses\": misses + misses2})\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            total_hits = 0\n",
    "            total_misses = 0\n",
    "\n",
    "            for i in range(100):\n",
    "                q1, q2 = multisetup()\n",
    "                t = Time(0)\n",
    "                c = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "                c2 = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "                c3 = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "                \n",
    "                r1 = compare_query_reward(q1, q_table, t, c, c2, c3) \n",
    "                r2 = compare_query_reward(q2, q_table, t, c, c2, c3)\n",
    "                \n",
    "                total_r = {}\n",
    "                for x, y in r1.items():\n",
    "                    total_r[x] = y\n",
    "\n",
    "                for x, y in r2.items():\n",
    "                    total_r[x] += y\n",
    "                    \n",
    "                tm = q1.time.now() + q2.time.now()\n",
    "                total_hits += total_r[\"hits_policy\"] / total_r[\"tm\"]\n",
    "                total_misses += total_r[\"misses_policy\"] / total_r[\"tm\"]\n",
    "            \n",
    "            reward_policy.append({\"Total Hits\": total_hits, \"Total Misses\": total_misses})\n",
    "            \n",
    "    return cum_reward_plot, q_values_cumulative, reward_policy\n",
    "    print(\"Training finished.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                      | 0/1000000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'join_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-84283b4327d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcum_reward_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_values_cumulative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_multiple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-6ff3e6646bae>\u001b[0m in \u001b[0;36mrun_multiple\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_runs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultisetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_queries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_time_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-7246d889bc80>\u001b[0m in \u001b[0;36mmultisetup\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_query_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mjoin_query\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_query_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mjoin_query\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'join_query' is not defined"
     ]
    }
   ],
   "source": [
    "cum_reward_plot, q_values_cumulative, reward = run_multiple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_reward(query_type):\n",
    "    \n",
    "    env = setup()\n",
    "    params_baseline = env.parameters.copy()\n",
    "    params_random = env.parameters.copy()\n",
    "    params_policy = env.parameters.copy()\n",
    "    \n",
    "    t = Time(0)\n",
    "    query_baseline = Query(query_type=query_type, parameters=params_baseline, time=t)\n",
    "    c = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "    query_baseline.set_query_cache(c)\n",
    "    \n",
    "    query_baseline_random = Query(query_type=query_type, parameters=params_random, time=t)\n",
    "    c2 = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "    query_baseline_random.set_query_cache(c2)\n",
    "    \n",
    "    query_policy = Query(query_type=query_type, parameters=params_policy, time=t)\n",
    "    c3 = Cache(cache_size, time=t, equate_id_to_value=True)\n",
    "    query_policy.set_query_cache(c3)\n",
    "    \n",
    "    hits_policy, misses_policy = evaluate_policy(query_policy, q_table)\n",
    "    hits_baseline, misses_baseline = get_baseline(query_baseline)\n",
    "    hits_random, misses_random = get_baseline(query_baseline_random, \"random\")\n",
    "    \n",
    "    return {\"hits_random\" : hits_random, \"misses_random\": misses_random, \n",
    "            \"hits_baseline\": hits_baseline, \"misses_baseline\": misses_baseline,\n",
    "           \"hits_policy\": hits_policy, \"misses_policy\": misses_policy, \"tm\": query_baseline.time.now()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1,q2=multisetup()\n",
    "filename=\"Figures/q1_{}_q2_{}_alpha_decay_{}_epsilon_greedy_{}_number_of_runs_{}_gamma_{}_trial_{}\".format(q1.query_type, q2.query_type,alpha_decay,epsilon_greedy,number_of_runs,gamma,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_metrics[\"Total Hits\"]).plot()\n",
    "plt.title(\"Number of hits for multiple sequential queries for empty cache\")\n",
    "plt.xlabel(\"Validation Run\")\n",
    "plt.ylabel(\"Hits\")\n",
    "plt.savefig(filename+\"Hits.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1, q2 = multisetup()\n",
    "\n",
    "# h1, miss1 = evaluate_policy(q1, q_table)\n",
    "# h2, miss2 = evaluate_policy(q2, q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h1, miss1, h2, miss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1, q2 = multisetup()\n",
    "# get_baseline(q1), get_baseline(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_value = pd.DataFrame(q_values_cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_q_value.min(), df_q_value.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cum_reward_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"r\"] = df[\"reward\"] / df[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reward.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"rolling_mean\"] = df[\"r\"].rolling(200).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_value = pd.DataFrame(q_values_cumulative)\n",
    "df_q_value.head()\n",
    "df_q_value[\"rolling\"] = df_q_value.rolling(1000).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_value.columns=[\"Absolute change in Q values\", \"Average change in Q values over 200 episodes\"]\n",
    "ax=df_q_value.plot(figsize=(20,5))\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Change in Q values\")\n",
    "plt.savefig(filename+\"Q_val.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['reward', 'Episodes', 'time', 'hits', 'misses', 'r', 'Rolling average of reward over 200 episodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=\"Rolling average of reward over 200 episodes\", x=\"Episodes\", figsize=(20, 10))\n",
    "plt.savefig(filename+\"Reward.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential = pd.DataFrame(q_table[66:111])\n",
    "join = pd.DataFrame(q_table[111:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_of_range=66\n",
    "end_of_range=111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(start_of_range, end_of_range):\n",
    "    farmers = [\"mru\", \"lru\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(q_table[start_of_range:end_of_range])\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(len(farmers)))\n",
    "    #ax.set_yticks(np.arange(len(vegetables)))\n",
    "    # ... and label them with the respective list entries\n",
    "    ax.set_xticklabels(farmers)\n",
    "    #ax.set_yticklabels(vegetables)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(q_table[start_of_range:end_of_range])):\n",
    "        for j in range(len(farmers)):\n",
    "            #print(q_table[66+i, j])\n",
    "            text = ax.text(j, i, round(q_table[start_of_range+i, j],2),\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "    fig.set_figheight(30)\n",
    "    fig.set_figwidth(20)\n",
    "    #ax.set_title(\"Harvest of local farmers (in tons/year)\")\n",
    "    plt.show()\n",
    "    fig.savefig(filename+\"r_\"+str(start_of_range)+\"_Heatmap.jpg\")\n",
    "    #Copy to clipboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in [66,11,111]:\n",
    "    generate_heatmap(r, r+20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def run_single():\n",
    "#     global epsilon\n",
    "    \n",
    "#     cum_reward_plot = []\n",
    "#     encoded_state = []\n",
    "\n",
    "#     for i in tqdm(range(1, number_of_runs)):\n",
    "\n",
    "#         env = setup()\n",
    "#         state = encode_queries(env.query_type, env.time.now(), max_time_steps)\n",
    "\n",
    "#         penalties, reward, = 0, 0\n",
    "#         done = False\n",
    "#         previous_hit, previous_miss = 0, 0\n",
    "#         cum_reward = 0\n",
    "#         tm = 0\n",
    "\n",
    "#         while not done:\n",
    "\n",
    "#             if random.uniform(0, 1) < epsilon:\n",
    "#                 action = random.choice(env.actions) # Explore action space\n",
    "#             else:\n",
    "#                 _action_ = np.argmax(q_table[state]) # Exploit learned values\n",
    "#                 action = \"mru\" if _action_ == 0 else \"lru\"\n",
    "\n",
    "#             hits, miss = env.step(action)\n",
    "#             next_state = encode_queries(env.query_type, env.time.now(), max_time_steps)\n",
    "#             encoded_state.append(next_state)\n",
    "\n",
    "#             reward = hits - previous_hit\n",
    "#             penalties = miss - previous_miss\n",
    "\n",
    "#             previous_hit = hits\n",
    "#             previous_miss = miss\n",
    "\n",
    "#             done = env.done\n",
    "\n",
    "#             _action_ = 0 if action == \"mru\" else 1\n",
    "\n",
    "#             old_value = q_table[state, _action_]\n",
    "#             next_max = np.max(q_table[next_state])\n",
    "\n",
    "#             r = reward - penalties\n",
    "#             new_value = (1 - alpha) * old_value + alpha * (r + gamma * next_max)\n",
    "#             q_table[state, _action_] = new_value\n",
    "#             state = next_state\n",
    "#             cum_reward += r\n",
    "#             tm += 1\n",
    "\n",
    "#         old_q = q_table.copy()\n",
    "\n",
    "#         cum_reward_plot.append({\"reward\": cum_reward, \"epoch\": i, \"time\": tm})\n",
    "\n",
    "#     print(\"Training finished.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1, q2 = multisetup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename+\".json\", \"w\") as f:\n",
    "    json.dump(q1.parameters, f)\n",
    "    json.dump(q2.parameters, f)\n",
    "    json.dump(max_time_steps, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table_df=pd.DataFrame(q_table[66:70])\n",
    "q_table_df.columns=[\"MRU\", \"LRU\"]\n",
    "print(q_table_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
